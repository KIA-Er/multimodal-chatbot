import base64
import io

import gradio as gr
from PIL import Image
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableWithMessageHistory
from multipart import file_path
from zai import ZhipuAiClient
from langchain_openai import ChatOpenAI
from main import get_final_chain, get_config
from config import get_settings
from langchain_community.chat_message_histories.postgres import PostgresChatMessageHistory

final_chain = get_final_chain()
config = get_config()
settings = get_settings()
'''ä½¿ç”¨Gradioåº“åˆ›å»ºä¸€ä¸ªç®€å•çš„Webç•Œé¢ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡æ–‡æœ¬å’Œè¯­éŸ³ä¸èŠå¤©æœºå™¨äººè¿›è¡Œäº¤äº’ã€‚'''
# TODO: å®ç°ç”¨æˆ·ç™»å½•åŠŸèƒ½ï¼Œä¸ºæ¯ä¸€ä¸ªç”¨æˆ·èµ‹äºˆä¸€ä¸ªsession_idï¼Œä»¥ä¾¿ä¿å­˜å’ŒåŒºåˆ†ä¸åŒç”¨æˆ·çš„èŠå¤©è®°å½•
# TODOï¼šæ¯æ¬¡ç”¨æˆ·ç™»å½•æ—¶ï¼Œå°†å†å²è®°å½•åŠ è½½åˆ°ç•Œé¢ä¸­æ˜¾ç¤ºå‡ºæ¥

#åˆå§‹åŒ–å…¨æ¨¡æ€å¤§æ¨¡å‹
llm = ChatOpenAI(
    model=settings.dashscope_model,
    api_key=settings.dashscope_api_key,
    base_url=settings.dashscope_base_url,
)

#åˆå§‹åŒ–prompt
prompt = ChatPromptTemplate.from_messages([
    ('system', 'ä½ æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿç†è§£ç”¨æˆ·å‘é€çš„æ–‡æœ¬ã€å›¾ç‰‡å’ŒéŸ³é¢‘æ¶ˆæ¯ï¼Œå¹¶è¿›è¡Œæœ‰æ„ä¹‰çš„å›å¤ã€‚å¹¶æ ¹æ®ç”¨æˆ·çš„è¾“å…¥å†…å®¹ï¼Œç»“åˆä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”Ÿæˆå‡†ç¡®ä¸”ç›¸å…³çš„å›ç­”ã€‚' ),
    MessagesPlaceholder(variable_name="messages")
])

chain = prompt | llm

DB_URI = "postgresql://{}:{}@{}:{}/{}?sslmode=disable".format(
settings.postgres_myusername,
settings.postgres_mypassword,
settings.postgres_host,
settings.postgres_port,
settings.postgres_mydatabase,
)

def get_session_history_from_postgres(session_id: str):
    # print(f"ğŸ§¾ æ­£åœ¨åŠ è½½å†å²è®°å½•ï¼Œsession_id = {session_id}")
    return PostgresChatMessageHistory(
        session_id=session_id,
        connection_string=DB_URI
    )

#é…ç½®å¸¦å†å²è®°å½•çš„å¤„ç†é“¾
chain_history = RunnableWithMessageHistory(
    chain,
    get_session_history_from_postgres,
)

#é…ç½®config
session_id = "KKZ"
config = {"configurable": {"session_id": session_id}}

# user_msg = HumanMessage([{'type': 'text', 'text': 'ä½ çŸ¥é“æœºå™¨å­¦ä¹ æ˜¯ä»€ä¹ˆä¸œè¥¿å—ï¼Ÿ'}])
# resp = chain_history.invoke({"messages":[user_msg]},config)
# print(resp)






def get_last_user_after_assistant(chat_history):
    """åå‘ä¾¿åˆ©æ‰¾åˆ°æœ€åä¸€ä¸ªassistantçš„ä½ç½®ï¼Œå¹¶è¿”å›åé¢çš„æ‰€æœ‰useræ¶ˆæ¯"""
    if not chat_history:
        return None
    if chat_history[-1]["role"] == "assistant":
        return None
    last_assistant_idx = -1
    for i in range(len(chat_history)-1, -1, -1):
        if chat_history[i]["role"] == "assistant":
            last_assistant_idx = i
            break
    #è‹¥æ²¡æ‰¾åˆ°assistant
    if last_assistant_idx == -1:
        return chat_history
    else:
        #ä»assistantä½ç½®å‘åæŸ¥æ‰¾ç¬¬ä¸€ä¸ªuser
        return chat_history[last_assistant_idx+1:]

#webç•Œé¢ä¸­çš„æ ¸å¿ƒå‡½æ•°
'''
å¤šæ¨¡æ€ç‰ˆæœ¬ add_message
'''
def add_message(chat_history, user_messages):
    """å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©å†å²è®°å½•ä¸­"""
    print(user_messages)
    for msg in user_messages['files']:
        print(msg)
        chat_history.append({'role': "user", 'content': {'path': msg}})
    #å¤„ç†æ–‡æœ¬æ¶ˆæ¯
    if user_messages['text'] is not None:
        chat_history.append({'role': "user", 'content': user_messages['text']})#å­—å…¸å†…çš„roleå¯¹åº”çš„å€¼å¿…é¡»æ˜¯"user"æˆ–è€…"assistant"
    return chat_history, gr.MultimodalTextbox(value=None, interactive=False)

#å¤„ç†è¯­éŸ³æ–‡ä»¶å‡½æ•°
def transcribe_audio(audio_path):
    """
    ä½¿ç”¨base64å¤„ç†è¯­éŸ³è½¬ä¸º
    ç›®å‰å…¨æ¨¡æ€å¤§æ¨¡å‹çš„ä¸¤ç§ä¼ å‚æ–¹å¼ï¼š1ã€base64å­—ç¬¦ä¸²ï¼ˆæœ¬åœ°ï¼‰ 2ã€ç½‘ç»œè®¿é—®çš„urlåœ°å€ï¼ˆå¤–ç½‘æœåŠ¡å™¨ä¸Šï¼‰å¦‚https://xxx.com/xx.wav
    """
    try:
        with open(audio_path,"rb") as audio_file:
            audio_data = base64.b64encode(audio_file.read()).decode('utf-8')
        audio_message = {
            "type": "audio_url",
            "audio_url": {
                "url": f"data:audio/wav;base64,{audio_data}",
                "duration": 30 #å•ä½ï¼šç§’ï¼ˆå¸®åŠ©æ¨¡å‹ä¼˜åŒ–å¤„ç†ï¼‰
            }
        }
        return audio_message
    except Exception as e:
        return {}

#å¤„ç†å›¾ç‰‡æ–‡ä»¶å‡½æ•°
def transcribe_image(image_path):
    """
    å°†ä»»æ„æ ¼å¼çš„å›¾ç‰‡è½¬æ¢ä¸ºbase64ç¼–ç çš„data URL
    :param image_path: å›¾ç‰‡æ–‡ä»¶çš„è·¯å¾„
    :return: åŒ…å«base64ç¼–ç çš„å­—å…¸
    """
    with Image.open(image_path) as img:
        #è·å–åŸå§‹å›¾ç‰‡æ ¼å¼ï¼ˆå¦‚JPEG/PNGï¼‰
        img_format = img.format if img.format else "JPEG"
        buffered = io.BytesIO()
        #ä¿ç•™åŸå§‹æ ¼å¼ä¿å­˜å›¾ç‰‡åˆ°å†…å­˜ç¼“å†²åŒº
        img.save(buffered, format=img_format)

        image_data = base64.b64encode(buffered.getvalue()).decode('utf-8')
        return {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/{img_format.lower()};base64,{image_data}",#MIMEç±»å‹æ ‡å‡†
                "detail": "low"
            }
        }

def submit_message(chat_history):
    """æäº¤ç”¨æˆ·æ¶ˆæ¯å¹¶è·å–èŠå¤©æœºå™¨äººçš„å“åº”"""
    user_messages = get_last_user_after_assistant(chat_history)
    print(user_messages)
    content = [] #HumanMessageçš„å†…å®¹
    if user_messages:
        for x in user_messages:
            if isinstance(x['content'], str):#æ–‡å­—è¾“å…¥æ¶ˆæ¯
                content.append({'type': 'text', 'text': x['content']})
            elif isinstance(x['content'], tuple):#å¤šæ¨¡æ€è¾“å…¥æ¶ˆæ¯
                file_path = x['content'][0]#å–å¾—ä¸Šä¼ æ–‡ä»¶çš„è·¯å¾„
                if file_path.endswith('.wav'):#æ˜¯å½•éŸ³æ–‡ä»¶
                    file_message = transcribe_audio(file_path)
                elif file_path.endswith('.jpg') or file_path.endswith('.png') or file_path.endswith('.jpeg'):#æ˜¯å›¾ç‰‡
                   file_message = transcribe_image(file_path)
                content.append(file_message)
            else:
                pass
        input_message = HumanMessage(content)
        resp = chain_history.invoke(
            {"messages": input_message},
            config=config
        )
        chat_history.append({'role': "assistant", 'content': resp.content})
    return chat_history


def execute_chain(chat_history):
    """æ‰§è¡ŒèŠå¤©é“¾ä»¥è·å–å“åº”"""
    print(chat_history)
    input = chat_history[-1]
    result = final_chain.invoke(
        {"input": input['content'], "config": config},
        config=config
    )
    chat_history.append({'role': "assistant", 'content': result.content})
    return chat_history

with gr.Blocks(title="å¤šæ¨¡æ€èŠå¤©æœºå™¨äºº", theme = gr.themes.Soft()) as block:

    #èŠå¤©å†å²è®°å½•çš„ç»„ä»¶
    chatbot = gr.Chatbot(type="messages", height=500, label = "èŠå¤©æœºå™¨äºº", bubble_full_width=False)

    #åˆ›å»ºå¤šæ¨¡æ€è¾“å…¥æ¡†
    chat_input = gr.MultimodalTextbox(
        interactive=True, #å¯äº¤äº’
        file_types=['image', '.wav', '.mp4'], #æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        file_count="multiple",#å…è®¸å¤šæ–‡ä»¶ä¸Šä¼ 
        placeholder="è¯·ç»™ChatBotè¾“å…¥ä¿¡æ¯æˆ–è€…ä¸Šä¼ æ–‡ä»¶...",#è¾“å…¥æ¡†ä½“æœ¯æ–‡æœ¬
        show_label=False,
        sources=["microphone", "upload",]#æ”¯æŒçš„è¾“å…¥æº:éº¦å…‹é£ä¸ä¸Šä¼ æ–‡ä»¶
    )

    chat_input.submit(
        add_message,
        [chatbot,chat_input],
        [chatbot,chat_input]
    ).then(
        submit_message,
        [chatbot],
        [chatbot],
    ).then( # å›å¤å®Œæˆåæ¿€æ´»è¾“å…¥æ¡†
        lambda: gr.MultimodalTextbox(interactive=True),
        None,#æ— è¾“å…¥
        [chat_input]#è¾“å‡ºåˆ°è¾“å…¥æ¡†
    )


    if __name__ == "__main__":
        block.launch()